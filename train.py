import os
import glob
import math
import numpy as np
import argparse
import dxchange
from utils import *
import model
import time
from keras.callbacks import TensorBoard
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from keras import backend as Keras
from keras.optimizers import SGD
from keras.optimizers import Adam
import cv2
from keras.models import load_model
from keras.callbacks import ModelCheckpoint
def is_image_file(filename):
    return any(filename.endswith(extension) for extension in [".tiff",".tif"])
def red_stack_tiff(path):
    # path0 = 'D:/pycharm/pycharm/py/resig/data/shapp3d_160/'
    files = os.listdir(path)
    prj = []
    # prj0 = np.zeros((len(files), size, size))
    for n,file in enumerate(files):
        if is_image_file(file):
            p = dxchange.read_tiff(path + file)
            prj.append(p)
    pr = np.array(prj)
    return pr
def get_best_checkpoint(self):
    """This function list all the current model checkpoint
    generated by the training and find the best one according
    to the monitored measure selected.

    Returns
    -------
        the best model checkpoint full path
    """

    # Monitored measure
    monitor = self._checkpoint_monitor

    # List the current checkpoints
    checkpoint_name = (self._trained_model_name + '-' +
                       self._starting_time + '*')
    checkpoint_path = os.path.join(
        self._trained_model_path,
        self._checkpoint_folder_name,
        checkpoint_name
    )
    checkpoint_list = glob.glob(checkpoint_path)

    # Extract the monitored measure value list from each checkpoint name
    measure = np.zeros(len(checkpoint_list))
    checkpoint_id = np.arange(len(checkpoint_list))
    for checkpoint, measure_id in zip(checkpoint_list, checkpoint_id):
        pos = checkpoint.rfind(monitor)
        if pos != -1:
            pos += len(monitor) + 1
            measure[measure_id] = float(checkpoint[pos:pos + 5])

    # Find the best monitored measure
    result_id = 0
    for monitor_itr, compare_itr in zip(self._monitor_list, self._monitor_list_eval):
        if monitor_itr == monitor:
            if compare_itr:
                result_id = measure.argmax()
            else:
                result_id = measure.argmin()

    return checkpoint_list[result_id]

def train():
    port_save_option = 1
    opt = get_args()
    input_x = red_stack_tiff(opt.train_dataroot)
    # input_x = red_stack_tiff(opt.train_dataroot + 'train_max/')
    # input_x = dxchange.read_tiff(opt.train_dataroot + 'train12_512.tiff')
    # where_are_inf = np.isnan(input_x)
    # # data1 = data
    # input_x[where_are_inf] = 0.0
    # input_x = red_stack_tiff(opt.train_dataroot)
    xr,xl,xc = input_x.shape
    input_x = input_x.reshape(xr,xl,xc,1)
    input_y = red_stack_tiff(opt.target_dataroot)
    # input_y = dxchange.read_tiff(opt.test_dataroot+'labels3_512.tiff')
    # input_y = dxchange.read_tiff(opt.test_dataroot + 'nmc_max_cray.tiff')
    # input_y2 = dxchange.read_tiff(opt.test_dataroot+'labels1_512.tiff')
    # input_y3 = dxchange.read_tiff(opt.test_dataroot+'labels3_512.tiff')
    # input_y4 = dxchange.read_tiff(opt.test_dataroot + 'lab2_4.tiff')
    # input_y = np.zeros((29,512,512,2))
    # input_y[:,:,:,0] = input_y1
    # input_y[:, :, :, 1] = input_y2
    # input_y[:, :, :, 2] = input_y3
    # input_y[:, :, :, 3] = input_y4
    # input_y = red_stack_tiff(opt.test_dataroot)
    input_y = input_y.reshape(xr, xl, xc, 1)
    input_x = preprocess_input(input_x)
    train_percentage = 100.0 - opt.split_valid_percentage
    train_percentage /= 100.0
    x_train, y_train, x_valid, y_valid = split_datasets(input_x, input_y,train_percentage)
    _, w, h, channel_nbrx = x_train.shape
    _, _, _, channel_nbry = y_train.shape

    num_training_data = len(x_train)
    num_val_data = len(x_valid)

    batch_size = opt.batch_size
    epochs = opt.epoch_num
    multiple_factor = opt.multiple_factor
    seed = 1

    steps_per_epoch = math.ceil(num_training_data / batch_size)
    validation_steps = math.ceil(num_val_data / batch_size)
    crop_w = int(np.floor(float(w) / float(multiple_factor)) * multiple_factor)
    crop_h = int(np.floor(float(h) / float(multiple_factor)) * multiple_factor)
    data_gen_args = dict(rotation_range=30,
                                        width_shift_range=0.8,
                                        height_shift_range=0.8,
                                        shear_range=0.1,
                                        zoom_range=0.1,
                                        horizontal_flip=True,
                                        vertical_flip=True,
                                        fill_mode='reflect')
    x_train_data_gen = ImageDataGenerator(**data_gen_args)
    y_train_data_gen = ImageDataGenerator(**data_gen_args)
    x_train_data_gen.fit(x_train, augment=True, seed=seed)
    y_train_data_gen.fit(y_train, augment=True, seed=seed)
    image_generator = x_train_data_gen.flow(
        x=x_train, batch_size=batch_size, shuffle=True, seed=seed)
    mask_generator = y_train_data_gen.flow(
        x=y_train, batch_size=batch_size, shuffle=True, seed=seed)
    train_gen = crop_generator(
        zip(image_generator, mask_generator), crop_w,
        crop_h, channel_nbrx,channel_nbry)
    val_data_gen = ImageDataGenerator(dict())
    valid_gen = val_data_gen.flow(
        x_valid, y_valid, num_val_data, shuffle=False)
    valid_gen_crop = crop_generator(
        valid_gen, crop_w, crop_h, channel_nbrx,channel_nbry)
    validation_data = next(valid_gen_crop)
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    Keras.set_session(tf.Session(config=config))
    network = model.unet(input_channel_num=channel_nbrx,output_class_nbr=2)

    optimizer = Adam(lr=opt.learning_rate)
    metrics = opt.training_metric
    network.compile(
        optimizer=optimizer,
        loss=opt.loss,
        metrics=[metrics ]
    )

    # Save the model architecture
    if not os.path.exists(opt.trained_model_path):
        os.makedirs(opt.trained_model_path)
    if not os.path.exists(opt.trained_model_path+'/tensorboard'):
        os.makedirs(opt.trained_model_path+'/tensorboard')
    archi_path = os.path.join(
        opt.trained_model_path, opt.trained_model_name + ".json")
    model_json = network.to_json()
    with open(archi_path, "w") as json_file:
        json_file.write(model_json)

    log_folder = os.path.join(
        opt.trained_model_path, opt.log_folder_name)
    log_name = opt.trained_model_name + '-' + time.strftime("%Y%m%d-%H%M%S")

    tensorboard_cb = TensorBoard(
        log_dir=os.path.join(log_folder, log_name),
        histogram_freq = 0,
        batch_size=opt.batch_size,
        write_graph=False,
        write_grads=False,
        write_images=False,
        embeddings_freq=0,
        embeddings_layer_names=None,
        embeddings_metadata=None)
    # model_path = opt.trained_model_path+'/'
    model_checkpoint1 = ModelCheckpoint(
        filepath=opt.trained_model_path+'/u_net1.hdf5',
        monitor='val_accuracy',
        verbose=1,
        save_best_only=True,
        save_weights_only=True,
        period=1
    )
    model_checkpoint2 = ModelCheckpoint(
        filepath=opt.trained_model_path + '/u_net2.hdf5',
        monitor='val_loss',
        verbose=1,
        save_best_only=True,
        save_weights_only=True,
        period=1
    )
    model_checkpoint = ModelCheckpoint(
        filepath=opt.trained_model_path + 'u_net_{epoch:03d}.hdf5',
        # monitor='val_loss',
        verbose=1,
        # save_best_only=True,
        save_weights_only=True,
        period=20
    )
    network.fit_generator(
            train_gen,
            validation_data=validation_data,
            epochs=epochs,
            steps_per_epoch=steps_per_epoch,
            validation_steps=validation_steps,
            verbose=2,
        callbacks = [tensorboard_cb]+[model_checkpoint]+[model_checkpoint2]+[model_checkpoint1])
    # pred = dxchange.read_tiff('F:/u_net/train_orss/slice113.tif.tiff')[tensorboard_cb]+
    # pred = cv2.resize(pred,(128,128))
    # pred = pred.reshape(1,128,128,1)
    # pred = preprocess_input(pred)
    # a = network.predict(pred)
    # a = a.reshape(1, 128,128)
    # dxchange.write_tiff(a,'F:/u_net/test4/out')

    # network.save_weights('F:/u_net/test5/unt11.hdf5')
    # clear_old_model(opt.trained_model_path, opt.trained_model_name)
    # if port_save_option != 0:
    #     trained_model_filename = get_best_checkpoint()
    #
    # # The best model checkpoint is copied in the main directory
    # _, extension = os.path.splitext(self._trained_model_filename)
    # final_saving_net_path = os.path.join(
    #     self._trained_model_path, self._trained_model_name)
    # final_saving_net_path += extension
    # shutil.copy(self._trained_model_filename,
    #             final_saving_net_path, follow_symlinks=True)
def get_args():
    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks',
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--train_dataroot', type=str,default='./')
    parser.add_argument('--target_dataroot', type=str, default='./')
    parser.add_argument('--batch_size',type=int, default=8)
    parser.add_argument('--epoch_num',type=int, default=44444)
    parser.add_argument('--split_valid_percentage', type=int, default=25)
    parser.add_argument('--multiple_factor',type=int, default=32)
    parser.add_argument('--loss', type=str, default='binary_crossentropy')
    parser.add_argument('--training_metric', type=str, default='accuracy')
    parser.add_argument('--learning_rate', type=float, default=0.0001)
    parser.add_argument('--trained_model_path', type=str, default='E:/u_net/test35_nmc_labmax_0331/model/')
    parser.add_argument('--trained_model_name', type=str, default='u-net')
    parser.add_argument('--log_folder_name', type=str, default='tensorboard')

    return parser.parse_args()


if __name__ == '__main__':
    train()
